{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame (rdf)\n",
    "rdf = pd.read_csv(r\"filtered_output.csv\")\n",
    "\n",
    "# Convert the 'Timestamp' column to datetime format\n",
    "rdf['Timestamp'] = pd.to_datetime(rdf['Timestamp'])\n",
    "\n",
    "# Format the 'Timestamp' column to include only hours, minutes, and seconds ('%H:%M:%S')\n",
    "rdf['Timestamp'] = rdf['Timestamp'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "# Group rdf by 'Timestamp' and aggregate each group as a list of values\n",
    "rdf_grouped = rdf.groupby('Timestamp').agg(lambda x: x.tolist()).reset_index()\n",
    "\n",
    "# Keep only the first pose for each second\n",
    "#rdf_grouped['Pose'] = rdf_grouped['Pose'].apply(lambda x: x[0] if x else None)\n",
    "\n",
    "# Set the 'Timestamp' column as the index\n",
    "rdf_grouped.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Save the resulting DataFrame (excluding the 'Time' column) to a new CSV file\n",
    "rdf_grouped.to_csv(\"aggregated_data_signal.csv\", header=True, columns=['Channel 1', 'Channel 2', 'Channel 3', 'Channel 4'])\n",
    "\n",
    "# Display the resulting DataFrame (rdf_grouped)\n",
    "print(rdf_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# Replace 'your_file.csv' with the actual path to your CSV file\n",
    "file_path = 'aggregated_data_signal.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Columns to consider\n",
    "channels = ['Channel 1', 'Channel 2', 'Channel 3', 'Channel 4']\n",
    "# Find the maximum number of elements across all cells in specified columns\n",
    "max_elements = max(df[channels].apply(lambda x: x.map(lambda y: len(eval(y)))).max())\n",
    "print(max_elements)\n",
    "\n",
    "for column in channels:\n",
    "    print(f\"Column: {column}\")\n",
    "    for index, cell_value in enumerate(df[column]):\n",
    "        cell_value = eval(cell_value)\n",
    "        # Generate indices for the expanded data\n",
    "        expanded_indices = np.linspace(0, len(cell_value) - 1, max_elements)\n",
    "        # Create a CubicSpline interpolation function\n",
    "        cubic_spline = CubicSpline(np.arange(len(cell_value)), cell_value, bc_type='clamped', extrapolate=False)\n",
    "        # Perform cubic spline interpolation on the expanded indices\n",
    "        expanded_data = cubic_spline(expanded_indices)\n",
    "        #print(f\"  Row {index + 1}: {cell_value}\")\n",
    "        df.at[index, column] = expanded_data.tolist()\n",
    "\n",
    "# Save the DataFrame to a new CSV file with interpolated values\n",
    "df.to_csv('interpolated_file_signal.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "\n",
    "# Replace 'your_file.csv' with the actual path to your CSV file\n",
    "file_path = 'aggregated_data_signal.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Columns to consider\n",
    "channels = ['Channel 1', 'Channel 2', 'Channel 3', 'Channel 4']\n",
    "\n",
    "# Find the maximum number of elements across all cells in specified columns\n",
    "#max_elements = max(df[channels].apply(lambda x: x.map(lambda y: len(eval(y)))).max())\n",
    "max_elements = 200\n",
    "print(max_elements)\n",
    "for column in channels:\n",
    "    print(f\"Column: {column}\")\n",
    "    for index, cell_value in enumerate(df[column]):\n",
    "        # Apply eval to each element (cell) within the Series\n",
    "        cell_value = eval(cell_value)\n",
    "        \n",
    "        # Generate indices for the expanded data\n",
    "        expanded_indices = np.linspace(0, len(cell_value) - 1, max_elements)\n",
    "        \n",
    "        # Create a PchipInterpolator interpolation function\n",
    "        pchip_interp = PchipInterpolator(np.arange(len(cell_value)), cell_value)\n",
    "        \n",
    "        # Perform Pchip interpolation on the expanded indices\n",
    "        expanded_data = pchip_interp(expanded_indices)\n",
    "        \n",
    "        # Update the DataFrame with interpolated values\n",
    "        df.at[index, column] = expanded_data.tolist()\n",
    "\n",
    "# Save the DataFrame to a new CSV file with interpolated values\n",
    "df.to_csv('interpolated_file_signal.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def expand_chn_data(df):\n",
    "    # Create an empty list to store DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over rows in the original DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        timestamp = row['Timestamp']\n",
    "\n",
    "        # Convert string of lists to actual lists\n",
    "        chn_1 = ast.literal_eval(row['Channel 1'])\n",
    "        chn_2 = ast.literal_eval(row['Channel 2'])\n",
    "        chn_3 = ast.literal_eval(row['Channel 3'])\n",
    "        chn_4 = ast.literal_eval(row['Channel 4'])\n",
    "\n",
    "        # Create a DataFrame for the current row\n",
    "        data = {\n",
    "            'Timestamp': [timestamp] * len(chn_1),\n",
    "            'Channel 1': chn_1,\n",
    "            'Channel 2': chn_2,\n",
    "            'Channel 3': chn_3,\n",
    "            'Channel 4': chn_4,\n",
    "        }\n",
    "        df_row = pd.DataFrame(data)\n",
    "\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df_row)\n",
    "\n",
    "    # Concatenate all DataFrames in the list\n",
    "    expanded_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return expanded_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Replace with the actual CSV file path\n",
    "    csv_filename = r\"interpolated_file_signal.csv\"\n",
    "    \n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    original_df = pd.read_csv(csv_filename)\n",
    "\n",
    "    # Expand the 'Chn' data into individual columns\n",
    "    expanded_df = expand_chn_data(original_df)\n",
    "\n",
    "    # Save the expanded DataFrame to a new CSV file\n",
    "    expanded_csv_filename = r\"C:\\Users\\Amarjith CK\\Downloads\\modified-matlab-code\\expanded_output_signal.csv\"\n",
    "    expanded_df.to_csv(expanded_csv_filename, index=False)\n",
    "\n",
    "    print(f\"Expanded data saved to {expanded_csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from the CSV file\n",
    "file_path = 'expanded_output_signal.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(file_path, parse_dates=['Timestamp'])\n",
    "channels = ['Channel 1', 'Channel 2', 'Channel 3', 'Channel 4']\n",
    "\n",
    "# Add 8000 to each channel value\n",
    "df[channels] = df[channels] + 8000\n",
    "\n",
    "# Save the modified data to a new CSV file\n",
    "df.to_csv(r'C:\\Users\\Amarjith CK\\Downloads\\modified-matlab-code\\modified_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122930.39"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.monotonic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
